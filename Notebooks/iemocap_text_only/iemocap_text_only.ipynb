{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8a13ac5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import wandb\n",
    "\n",
    "wandb.login()\n",
    "\n",
    "# setup wandb environment variables\n",
    "%env WANDB_ENTITY=meghanadh27/btp_sa\n",
    "%env WANDB_PROJECT=finetune_distilbert_iemocap_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ec5d8c85",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found cached dataset parquet (/Users/meghanadhpulivarthi/.cache/huggingface/datasets/Zahra99___parquet/Zahra99--IEMOCAP_Text-96d9699f03987401/0.0.0/2a3b91fbd88a2c90d1dbbb32b460cf621d31bd5b05b934492fdef7d8d6f236ec)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bf58cf86c34342d5a5d511dde95ec035",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from datasets import load_dataset, concatenate_datasets, DatasetDict\n",
    "\n",
    "dataset = load_dataset(\"Zahra99/IEMOCAP_Text\")\n",
    "dataset = concatenate_datasets([dataset[\"session1\"], dataset[\"session2\"], dataset[\"session3\"], dataset[\"session4\"], dataset[\"session5\"]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "efb5d5db",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ClassLabel(names=['ang', 'hap', 'neu', 'sad'], id=None)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.features[\"label\"] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3a400101-d6b6-4c48-9672-ae80ae5b15f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 90% train, 10% test + validation\n",
    "train_test_dataset = dataset.train_test_split(test_size=0.2)\n",
    "# Split the 10% test + valid in half test, half valid\n",
    "test_valid = train_test_dataset['test'].train_test_split(test_size=0.5)\n",
    "# gather everyone if you want to have a single DatasetDict\n",
    "train_test_valid_dataset = DatasetDict({\n",
    "    'train': train_test_dataset['train'].select([0, 1, 2, 3, 4]),\n",
    "    'validation': test_valid['train'],\n",
    "    'test': test_valid['test']})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "37272cf2-29ab-4318-99e6-4a635ea2502b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['text', 'label'],\n",
       "        num_rows: 5\n",
       "    })\n",
       "    validation: Dataset({\n",
       "        features: ['text', 'label'],\n",
       "        num_rows: 553\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['text', 'label'],\n",
       "        num_rows: 554\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_test_valid_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "584f31ea-b886-4e1b-8934-cc449f38428f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'text': \"Penny slots. That's what he plays.\", 'label': 2}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_test_valid_dataset[\"train\"][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c51936f3-d13b-4e15-a042-2141a9baae13",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'neu'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "id2label_fn = train_test_valid_dataset[\"train\"].features[\"label\"].int2str\n",
    "id2label_fn(train_test_valid_dataset[\"train\"][0][\"label\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5bc57f2a-cc31-4182-8d23-44818b18df8d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f2eb8dfb12024c40a12e11fea5b35966",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/5 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "785f2e5e013a471ea0c1053a0ec18b86",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/553 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6b4508a3a90b4fe1a1d680ede7b8041a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/554 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from transformers import AutoTokenizer, DataCollatorWithPadding\n",
    "checkpoint = \"distilbert-base-uncased\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(checkpoint)\n",
    "\n",
    "def tokenize_function(examples):\n",
    "   return tokenizer(examples[\"text\"], truncation=True)\n",
    "    \n",
    "tokenized_datasets = train_test_valid_dataset.map(tokenize_function, batched=True)\n",
    "data_collator = DataCollatorWithPadding(tokenizer=tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "cbcbf980-5c5e-4334-8386-ab40104a7191",
   "metadata": {},
   "outputs": [],
   "source": [
    "import evaluate\n",
    "import numpy as np\n",
    "from datasets import load_metric\n",
    "\n",
    "def compute_metrics(eval_preds):\n",
    "#     metric = evaluate.combine([\"accuracy\", \"recall\", \"precision\", \"f1\"])\n",
    "#     logits, labels = eval_preds\n",
    "#     predictions = np.argmax(logits, axis=-1)\n",
    "#     return metric.compute(predictions=predictions, references=labels, average=\"weighted\")\n",
    "    load_accuracy = load_metric(\"accuracy\")\n",
    "    load_f1 = load_metric(\"f1\")\n",
    "  \n",
    "    logits, labels = eval_preds\n",
    "    predictions = np.argmax(logits, axis=-1)\n",
    "    accuracy = load_accuracy.compute(predictions=predictions, references=labels)[\"accuracy\"]\n",
    "    f1 = load_f1.compute(predictions=predictions, references=labels, average=\"weighted\")[\"f1\"]\n",
    "    return {\"accuracy\": accuracy, \"f1\": f1}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "98c663a1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6fcc3214ab0e406da3720bbbc1cdf51e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HTML(value='<center> <img\\nsrc=https://huggingface.co/front/assets/huggingface_logo-noborder.svâ€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from huggingface_hub import notebook_login\n",
    "\n",
    "notebook_login()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "eb66add0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "meghanadh\n"
     ]
    }
   ],
   "source": [
    "!huggingface-cli whoami"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e4e1c305-6c24-4d34-b7db-e98f04f63d89",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'neu'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "id2label = {\n",
    "    str(i): id2label_fn(i)\n",
    "    for i in range(len(tokenized_datasets[\"train\"].features[\"label\"].names))\n",
    "}\n",
    "label2id = {v: k for k, v in id2label.items()}\n",
    "id2label[\"2\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9b7e01c7-0999-4389-8ca4-9214d3266665",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1.], device='mps:0')\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "if torch.backends.mps.is_available():\n",
    "    mps_device = torch.device(\"mps\")\n",
    "    x = torch.ones(1, device=mps_device)\n",
    "    print (x)\n",
    "else:\n",
    "    print (\"MPS device not found.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6d8106b2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/meghanadhpulivarthi/opt/anaconda3/lib/python3.11/site-packages/transformers/training_args.py:1951: UserWarning: `use_mps_device` is deprecated and will be removed in version 5.0 of ðŸ¤— Transformers. `mps` device will be used by default if available similar to the way `cuda` device is used.Therefore, no action from user is required. \n",
      "  warnings.warn(\n",
      "/Users/meghanadhpulivarthi/opt/anaconda3/lib/python3.11/site-packages/accelerate/accelerator.py:432: FutureWarning: Passing the following arguments to `Accelerator` is deprecated and will be removed in version 1.0 of Accelerate: dict_keys(['dispatch_batches', 'split_batches', 'even_batches', 'use_seedable_sampler']). Please pass an `accelerate.DataLoaderConfiguration` instead: \n",
      "dataloader_config = DataLoaderConfiguration(dispatch_batches=None, split_batches=False, even_batches=True, use_seedable_sampler=True)\n",
      "  warnings.warn(\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    }
   ],
   "source": [
    "from transformers import TrainingArguments, AutoModelForSequenceClassification, Trainer, EarlyStoppingCallback\n",
    "\n",
    "training_args = TrainingArguments(\n",
    "    \"finetune_bert_iemocap_text\", \n",
    "    evaluation_strategy=\"epoch\", \n",
    "    num_train_epochs=10,\n",
    "    save_strategy=\"epoch\",\n",
    "    save_total_limit=2,\n",
    "    logging_steps=40,\n",
    "    load_best_model_at_end=True,\n",
    "    metric_for_best_model=\"accuracy\",\n",
    "    # use_mps_device=True,\n",
    "    overwrite_output_dir=True,\n",
    "    push_to_hub=True\n",
    ")\n",
    "\n",
    "checkpoint = \"/Users/meghanadhpulivarthi/Desktop/BTProject/Notebooks/iemocap_text_only/finetune_bert_iemocap_text/checkpoint-2212\"\n",
    "num_labels = len(id2label)\n",
    "model = AutoModelForSequenceClassification.from_pretrained(\n",
    "    checkpoint, \n",
    "    num_labels=num_labels,\n",
    "    label2id=label2id,\n",
    "    id2label=id2label,\n",
    ")\n",
    "\n",
    "trainer = Trainer(\n",
    "    model,\n",
    "    training_args,\n",
    "    train_dataset=tokenized_datasets[\"train\"],\n",
    "    eval_dataset=tokenized_datasets[\"validation\"],\n",
    "    data_collator=data_collator,\n",
    "    tokenizer=tokenizer,\n",
    "    compute_metrics=compute_metrics,\n",
    "    callbacks = [EarlyStoppingCallback(early_stopping_patience=3 )],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "aaa1c9ea",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='6' max='10' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [ 6/10 00:50 < 00:50, 0.08 it/s, Epoch 5/10]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>1.400554</td>\n",
       "      <td>0.179024</td>\n",
       "      <td>0.103222</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>No log</td>\n",
       "      <td>1.411433</td>\n",
       "      <td>0.200723</td>\n",
       "      <td>0.119306</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>No log</td>\n",
       "      <td>1.428031</td>\n",
       "      <td>0.182640</td>\n",
       "      <td>0.107722</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>No log</td>\n",
       "      <td>1.445064</td>\n",
       "      <td>0.189873</td>\n",
       "      <td>0.109053</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>No log</td>\n",
       "      <td>1.485121</td>\n",
       "      <td>0.173285</td>\n",
       "      <td>0.089996</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>\n",
       "    <div>\n",
       "      \n",
       "      <progress value='70' max='70' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [70/70 00:04]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/meghanadhpulivarthi/opt/anaconda3/lib/python3.11/site-packages/datasets/load.py:756: FutureWarning: The repository for accuracy contains custom code which must be executed to correctly load the metric. You can inspect the repository content at https://raw.githubusercontent.com/huggingface/datasets/2.18.0/metrics/accuracy/accuracy.py\n",
      "You can avoid this message in future by passing the argument `trust_remote_code=True`.\n",
      "Passing `trust_remote_code=True` will be mandatory to load this metric from the next major release of `datasets`.\n",
      "  warnings.warn(\n",
      "/Users/meghanadhpulivarthi/opt/anaconda3/lib/python3.11/site-packages/datasets/load.py:756: FutureWarning: The repository for f1 contains custom code which must be executed to correctly load the metric. You can inspect the repository content at https://raw.githubusercontent.com/huggingface/datasets/2.18.0/metrics/f1/f1.py\n",
      "You can avoid this message in future by passing the argument `trust_remote_code=True`.\n",
      "Passing `trust_remote_code=True` will be mandatory to load this metric from the next major release of `datasets`.\n",
      "  warnings.warn(\n",
      "/Users/meghanadhpulivarthi/opt/anaconda3/lib/python3.11/site-packages/datasets/load.py:756: FutureWarning: The repository for accuracy contains custom code which must be executed to correctly load the metric. You can inspect the repository content at https://raw.githubusercontent.com/huggingface/datasets/2.18.0/metrics/accuracy/accuracy.py\n",
      "You can avoid this message in future by passing the argument `trust_remote_code=True`.\n",
      "Passing `trust_remote_code=True` will be mandatory to load this metric from the next major release of `datasets`.\n",
      "  warnings.warn(\n",
      "/Users/meghanadhpulivarthi/opt/anaconda3/lib/python3.11/site-packages/datasets/load.py:756: FutureWarning: The repository for f1 contains custom code which must be executed to correctly load the metric. You can inspect the repository content at https://raw.githubusercontent.com/huggingface/datasets/2.18.0/metrics/f1/f1.py\n",
      "You can avoid this message in future by passing the argument `trust_remote_code=True`.\n",
      "Passing `trust_remote_code=True` will be mandatory to load this metric from the next major release of `datasets`.\n",
      "  warnings.warn(\n",
      "/Users/meghanadhpulivarthi/opt/anaconda3/lib/python3.11/site-packages/datasets/load.py:756: FutureWarning: The repository for accuracy contains custom code which must be executed to correctly load the metric. You can inspect the repository content at https://raw.githubusercontent.com/huggingface/datasets/2.18.0/metrics/accuracy/accuracy.py\n",
      "You can avoid this message in future by passing the argument `trust_remote_code=True`.\n",
      "Passing `trust_remote_code=True` will be mandatory to load this metric from the next major release of `datasets`.\n",
      "  warnings.warn(\n",
      "/Users/meghanadhpulivarthi/opt/anaconda3/lib/python3.11/site-packages/datasets/load.py:756: FutureWarning: The repository for f1 contains custom code which must be executed to correctly load the metric. You can inspect the repository content at https://raw.githubusercontent.com/huggingface/datasets/2.18.0/metrics/f1/f1.py\n",
      "You can avoid this message in future by passing the argument `trust_remote_code=True`.\n",
      "Passing `trust_remote_code=True` will be mandatory to load this metric from the next major release of `datasets`.\n",
      "  warnings.warn(\n",
      "/Users/meghanadhpulivarthi/opt/anaconda3/lib/python3.11/site-packages/datasets/load.py:756: FutureWarning: The repository for accuracy contains custom code which must be executed to correctly load the metric. You can inspect the repository content at https://raw.githubusercontent.com/huggingface/datasets/2.18.0/metrics/accuracy/accuracy.py\n",
      "You can avoid this message in future by passing the argument `trust_remote_code=True`.\n",
      "Passing `trust_remote_code=True` will be mandatory to load this metric from the next major release of `datasets`.\n",
      "  warnings.warn(\n",
      "/Users/meghanadhpulivarthi/opt/anaconda3/lib/python3.11/site-packages/datasets/load.py:756: FutureWarning: The repository for f1 contains custom code which must be executed to correctly load the metric. You can inspect the repository content at https://raw.githubusercontent.com/huggingface/datasets/2.18.0/metrics/f1/f1.py\n",
      "You can avoid this message in future by passing the argument `trust_remote_code=True`.\n",
      "Passing `trust_remote_code=True` will be mandatory to load this metric from the next major release of `datasets`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[14], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m trainer\u001b[38;5;241m.\u001b[39mtrain()\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.11/site-packages/transformers/trainer.py:1615\u001b[0m, in \u001b[0;36mTrainer.train\u001b[0;34m(self, resume_from_checkpoint, trial, ignore_keys_for_eval, **kwargs)\u001b[0m\n\u001b[1;32m   1612\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1613\u001b[0m     \u001b[38;5;66;03m# Disable progress bars when uploading models during checkpoints to avoid polluting stdout\u001b[39;00m\n\u001b[1;32m   1614\u001b[0m     hf_hub_utils\u001b[38;5;241m.\u001b[39mdisable_progress_bars()\n\u001b[0;32m-> 1615\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m inner_training_loop(\n\u001b[1;32m   1616\u001b[0m         args\u001b[38;5;241m=\u001b[39margs,\n\u001b[1;32m   1617\u001b[0m         resume_from_checkpoint\u001b[38;5;241m=\u001b[39mresume_from_checkpoint,\n\u001b[1;32m   1618\u001b[0m         trial\u001b[38;5;241m=\u001b[39mtrial,\n\u001b[1;32m   1619\u001b[0m         ignore_keys_for_eval\u001b[38;5;241m=\u001b[39mignore_keys_for_eval,\n\u001b[1;32m   1620\u001b[0m     )\n\u001b[1;32m   1621\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m   1622\u001b[0m     hf_hub_utils\u001b[38;5;241m.\u001b[39menable_progress_bars()\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.11/site-packages/transformers/trainer.py:2049\u001b[0m, in \u001b[0;36mTrainer._inner_training_loop\u001b[0;34m(self, batch_size, args, resume_from_checkpoint, trial, ignore_keys_for_eval)\u001b[0m\n\u001b[1;32m   2046\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcontrol\u001b[38;5;241m.\u001b[39mshould_training_stop \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m   2048\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcontrol \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcallback_handler\u001b[38;5;241m.\u001b[39mon_epoch_end(args, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcontrol)\n\u001b[0;32m-> 2049\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_maybe_log_save_evaluate(tr_loss, grad_norm, model, trial, epoch, ignore_keys_for_eval)\n\u001b[1;32m   2051\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m DebugOption\u001b[38;5;241m.\u001b[39mTPU_METRICS_DEBUG \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs\u001b[38;5;241m.\u001b[39mdebug:\n\u001b[1;32m   2052\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m is_torch_tpu_available():\n\u001b[1;32m   2053\u001b[0m         \u001b[38;5;66;03m# tpu-comment: Logging debug metrics for PyTorch/XLA (compile, execute times, ops, etc.)\u001b[39;00m\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.11/site-packages/transformers/trainer.py:2412\u001b[0m, in \u001b[0;36mTrainer._maybe_log_save_evaluate\u001b[0;34m(self, tr_loss, grad_norm, model, trial, epoch, ignore_keys_for_eval)\u001b[0m\n\u001b[1;32m   2410\u001b[0m metrics \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   2411\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcontrol\u001b[38;5;241m.\u001b[39mshould_evaluate:\n\u001b[0;32m-> 2412\u001b[0m     metrics \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mevaluate(ignore_keys\u001b[38;5;241m=\u001b[39mignore_keys_for_eval)\n\u001b[1;32m   2413\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_report_to_hp_search(trial, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate\u001b[38;5;241m.\u001b[39mglobal_step, metrics)\n\u001b[1;32m   2415\u001b[0m     \u001b[38;5;66;03m# Run delayed LR scheduler now that metrics are populated\u001b[39;00m\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.11/site-packages/transformers/trainer.py:3229\u001b[0m, in \u001b[0;36mTrainer.evaluate\u001b[0;34m(self, eval_dataset, ignore_keys, metric_key_prefix)\u001b[0m\n\u001b[1;32m   3226\u001b[0m start_time \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime()\n\u001b[1;32m   3228\u001b[0m eval_loop \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprediction_loop \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs\u001b[38;5;241m.\u001b[39muse_legacy_prediction_loop \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mevaluation_loop\n\u001b[0;32m-> 3229\u001b[0m output \u001b[38;5;241m=\u001b[39m eval_loop(\n\u001b[1;32m   3230\u001b[0m     eval_dataloader,\n\u001b[1;32m   3231\u001b[0m     description\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mEvaluation\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   3232\u001b[0m     \u001b[38;5;66;03m# No point gathering the predictions if there are no metrics, otherwise we defer to\u001b[39;00m\n\u001b[1;32m   3233\u001b[0m     \u001b[38;5;66;03m# self.args.prediction_loss_only\u001b[39;00m\n\u001b[1;32m   3234\u001b[0m     prediction_loss_only\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcompute_metrics \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m   3235\u001b[0m     ignore_keys\u001b[38;5;241m=\u001b[39mignore_keys,\n\u001b[1;32m   3236\u001b[0m     metric_key_prefix\u001b[38;5;241m=\u001b[39mmetric_key_prefix,\n\u001b[1;32m   3237\u001b[0m )\n\u001b[1;32m   3239\u001b[0m total_batch_size \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs\u001b[38;5;241m.\u001b[39meval_batch_size \u001b[38;5;241m*\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs\u001b[38;5;241m.\u001b[39mworld_size\n\u001b[1;32m   3240\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmetric_key_prefix\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m_jit_compilation_time\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m output\u001b[38;5;241m.\u001b[39mmetrics:\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.11/site-packages/transformers/trainer.py:3440\u001b[0m, in \u001b[0;36mTrainer.evaluation_loop\u001b[0;34m(self, dataloader, description, prediction_loss_only, ignore_keys, metric_key_prefix)\u001b[0m\n\u001b[1;32m   3434\u001b[0m     inputs_host \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m   3435\u001b[0m         inputs_decode\n\u001b[1;32m   3436\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m inputs_host \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   3437\u001b[0m         \u001b[38;5;28;01melse\u001b[39;00m nested_concat(inputs_host, inputs_decode, padding_index\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m100\u001b[39m)\n\u001b[1;32m   3438\u001b[0m     )\n\u001b[1;32m   3439\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m logits \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m-> 3440\u001b[0m     logits \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maccelerator\u001b[38;5;241m.\u001b[39mpad_across_processes(logits, dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m, pad_index\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m100\u001b[39m)\n\u001b[1;32m   3441\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpreprocess_logits_for_metrics \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   3442\u001b[0m         logits \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpreprocess_logits_for_metrics(logits, labels)\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.11/site-packages/accelerate/accelerator.py:2338\u001b[0m, in \u001b[0;36mAccelerator.pad_across_processes\u001b[0;34m(self, tensor, dim, pad_index, pad_first)\u001b[0m\n\u001b[1;32m   2305\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mpad_across_processes\u001b[39m(\u001b[38;5;28mself\u001b[39m, tensor, dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m, pad_index\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m, pad_first\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m):\n\u001b[1;32m   2306\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   2307\u001b[0m \u001b[38;5;124;03m    Recursively pad the tensors in a nested list/tuple/dictionary of tensors from all devices to the same size so\u001b[39;00m\n\u001b[1;32m   2308\u001b[0m \u001b[38;5;124;03m    they can safely be gathered.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   2336\u001b[0m \u001b[38;5;124;03m    ```\u001b[39;00m\n\u001b[1;32m   2337\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m-> 2338\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m pad_across_processes(tensor, dim\u001b[38;5;241m=\u001b[39mdim, pad_index\u001b[38;5;241m=\u001b[39mpad_index, pad_first\u001b[38;5;241m=\u001b[39mpad_first)\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.11/site-packages/accelerate/utils/operations.py:414\u001b[0m, in \u001b[0;36mchained_operation.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    411\u001b[0m \u001b[38;5;129m@wraps\u001b[39m(function)\n\u001b[1;32m    412\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mwrapper\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m    413\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 414\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m function(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    415\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m DistributedOperationException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    416\u001b[0m         operation \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfunction\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__module__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfunction\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.11/site-packages/accelerate/utils/operations.py:681\u001b[0m, in \u001b[0;36mpad_across_processes\u001b[0;34m(tensor, dim, pad_index, pad_first)\u001b[0m\n\u001b[1;32m    678\u001b[0m     new_tensor[indices] \u001b[38;5;241m=\u001b[39m tensor\n\u001b[1;32m    679\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m new_tensor\n\u001b[0;32m--> 681\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m recursively_apply(\n\u001b[1;32m    682\u001b[0m     _pad_across_processes, tensor, error_on_other_type\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, dim\u001b[38;5;241m=\u001b[39mdim, pad_index\u001b[38;5;241m=\u001b[39mpad_index, pad_first\u001b[38;5;241m=\u001b[39mpad_first\n\u001b[1;32m    683\u001b[0m )\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.11/site-packages/accelerate/utils/operations.py:126\u001b[0m, in \u001b[0;36mrecursively_apply\u001b[0;34m(func, data, test_type, error_on_other_type, *args, **kwargs)\u001b[0m\n\u001b[1;32m    117\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mtype\u001b[39m(data)(\n\u001b[1;32m    118\u001b[0m         {\n\u001b[1;32m    119\u001b[0m             k: recursively_apply(\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    123\u001b[0m         }\n\u001b[1;32m    124\u001b[0m     )\n\u001b[1;32m    125\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m test_type(data):\n\u001b[0;32m--> 126\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m func(data, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    127\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m error_on_other_type:\n\u001b[1;32m    128\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\n\u001b[1;32m    129\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUnsupported types (\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mtype\u001b[39m(data)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m) passed to `\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfunc\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m`. Only nested list/tuple/dicts of \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    130\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mobjects that are valid for `\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtest_type\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m` should be passed.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    131\u001b[0m     )\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.11/site-packages/accelerate/utils/operations.py:661\u001b[0m, in \u001b[0;36mpad_across_processes.<locals>._pad_across_processes\u001b[0;34m(tensor, dim, pad_index, pad_first)\u001b[0m\n\u001b[1;32m    658\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m tensor\n\u001b[1;32m    660\u001b[0m \u001b[38;5;66;03m# Gather all sizes\u001b[39;00m\n\u001b[0;32m--> 661\u001b[0m size \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mtensor(tensor\u001b[38;5;241m.\u001b[39mshape, device\u001b[38;5;241m=\u001b[39mtensor\u001b[38;5;241m.\u001b[39mdevice)[\u001b[38;5;28;01mNone\u001b[39;00m]\n\u001b[1;32m    662\u001b[0m sizes \u001b[38;5;241m=\u001b[39m gather(size)\u001b[38;5;241m.\u001b[39mcpu()\n\u001b[1;32m    663\u001b[0m \u001b[38;5;66;03m# Then pad to the maximum size\u001b[39;00m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "849f23f4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='140' max='70' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [70/70 00:36]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/r4/bfd090qs4pv5yxgksftt53ym0000gp/T/ipykernel_98982/624319701.py:10: FutureWarning: load_metric is deprecated and will be removed in the next major version of datasets. Use 'evaluate.load' instead, from the new library ðŸ¤— Evaluate: https://huggingface.co/docs/evaluate\n",
      "  load_accuracy = load_metric(\"accuracy\")\n",
      "/Users/meghanadhpulivarthi/opt/anaconda3/lib/python3.11/site-packages/datasets/load.py:756: FutureWarning: The repository for accuracy contains custom code which must be executed to correctly load the metric. You can inspect the repository content at https://raw.githubusercontent.com/huggingface/datasets/2.18.0/metrics/accuracy/accuracy.py\n",
      "You can avoid this message in future by passing the argument `trust_remote_code=True`.\n",
      "Passing `trust_remote_code=True` will be mandatory to load this metric from the next major release of `datasets`.\n",
      "  warnings.warn(\n",
      "/Users/meghanadhpulivarthi/opt/anaconda3/lib/python3.11/site-packages/datasets/load.py:756: FutureWarning: The repository for f1 contains custom code which must be executed to correctly load the metric. You can inspect the repository content at https://raw.githubusercontent.com/huggingface/datasets/2.18.0/metrics/f1/f1.py\n",
      "You can avoid this message in future by passing the argument `trust_remote_code=True`.\n",
      "Passing `trust_remote_code=True` will be mandatory to load this metric from the next major release of `datasets`.\n",
      "  warnings.warn(\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mmeghanadh27\u001b[0m (\u001b[33mbtp_sa\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6254c0b20e2f428282edf010c914491d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='Waiting for wandb.init()...\\r'), FloatProgress(value=0.01112462546653761, max=1.0)â€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.16.4"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/Users/meghanadhpulivarthi/Desktop/BTProject/Notebooks/iemocap_text_only/wandb/run-20240320_120828-3uh4rdap</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/btp_sa/huggingface/runs/3uh4rdap' target=\"_blank\">frosty-valley-10</a></strong> to <a href='https://wandb.ai/btp_sa/huggingface' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/btp_sa/huggingface' target=\"_blank\">https://wandb.ai/btp_sa/huggingface</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/btp_sa/huggingface/runs/3uh4rdap' target=\"_blank\">https://wandb.ai/btp_sa/huggingface/runs/3uh4rdap</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'eval_loss': 0.49315324425697327,\n",
       " 'eval_accuracy': 0.8752260397830018,\n",
       " 'eval_f1': 0.8755214168723158,\n",
       " 'eval_runtime': 12.3909,\n",
       " 'eval_samples_per_second': 44.629,\n",
       " 'eval_steps_per_second': 5.649}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.evaluate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "af481cb8-4eda-42de-8a15-0dac801c7103",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/meghanadhpulivarthi/opt/anaconda3/lib/python3.11/site-packages/datasets/load.py:756: FutureWarning: The repository for accuracy contains custom code which must be executed to correctly load the metric. You can inspect the repository content at https://raw.githubusercontent.com/huggingface/datasets/2.18.0/metrics/accuracy/accuracy.py\n",
      "You can avoid this message in future by passing the argument `trust_remote_code=True`.\n",
      "Passing `trust_remote_code=True` will be mandatory to load this metric from the next major release of `datasets`.\n",
      "  warnings.warn(\n",
      "/Users/meghanadhpulivarthi/opt/anaconda3/lib/python3.11/site-packages/datasets/load.py:756: FutureWarning: The repository for f1 contains custom code which must be executed to correctly load the metric. You can inspect the repository content at https://raw.githubusercontent.com/huggingface/datasets/2.18.0/metrics/f1/f1.py\n",
      "You can avoid this message in future by passing the argument `trust_remote_code=True`.\n",
      "Passing `trust_remote_code=True` will be mandatory to load this metric from the next major release of `datasets`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'eval_loss': 0.4672025144100189,\n",
       " 'eval_accuracy': 0.868231046931408,\n",
       " 'eval_f1': 0.8691378208703979,\n",
       " 'eval_runtime': 9.9975,\n",
       " 'eval_samples_per_second': 55.414,\n",
       " 'eval_steps_per_second': 7.002}"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.evaluate(eval_dataset=tokenized_datasets[\"test\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "ac3b664f-301d-450b-8f4f-7d0703f25e6e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/meghanadhpulivarthi/opt/anaconda3/lib/python3.11/site-packages/datasets/load.py:756: FutureWarning: The repository for accuracy contains custom code which must be executed to correctly load the metric. You can inspect the repository content at https://raw.githubusercontent.com/huggingface/datasets/2.18.0/metrics/accuracy/accuracy.py\n",
      "You can avoid this message in future by passing the argument `trust_remote_code=True`.\n",
      "Passing `trust_remote_code=True` will be mandatory to load this metric from the next major release of `datasets`.\n",
      "  warnings.warn(\n",
      "/Users/meghanadhpulivarthi/opt/anaconda3/lib/python3.11/site-packages/datasets/load.py:756: FutureWarning: The repository for f1 contains custom code which must be executed to correctly load the metric. You can inspect the repository content at https://raw.githubusercontent.com/huggingface/datasets/2.18.0/metrics/f1/f1.py\n",
      "You can avoid this message in future by passing the argument `trust_remote_code=True`.\n",
      "Passing `trust_remote_code=True` will be mandatory to load this metric from the next major release of `datasets`.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "test_preds = trainer.predict(tokenized_datasets[\"test\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "9c474913-04bd-401f-95ca-b50d43fad672",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([3, 0, 0, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 0, 3, 0, 3, 3, 3, 3,\n",
       "       3, 0, 3, 3, 3, 0, 3, 3, 3, 3, 0, 3, 0, 0, 3, 3, 3, 0, 3, 0, 0, 3,\n",
       "       3, 3, 3, 3, 3, 3, 3, 3, 3, 0, 3, 3, 3, 3, 0, 3, 3, 3, 3, 3, 0, 3,\n",
       "       3, 0, 3, 3, 0, 3, 3, 3, 0, 0, 3, 3, 0, 3, 0, 3, 3, 3, 0, 3, 3, 3,\n",
       "       0, 0, 3, 0, 3, 3, 3, 3, 3, 3, 0, 3, 3, 3, 3, 3, 3, 0, 3, 3, 3, 0,\n",
       "       3, 0, 3, 3, 3, 0, 3, 3, 3, 0, 3, 0, 3, 3, 3, 3, 3, 3, 3, 3, 0, 0,\n",
       "       0, 3, 0, 3, 0, 0, 0, 0, 3, 3, 0, 0, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,\n",
       "       3, 3, 0, 0, 3, 3, 3, 3, 3, 3, 3, 3, 0, 3, 0, 0, 3, 0, 3, 3, 3, 3,\n",
       "       0, 3, 3, 3, 3, 3, 3, 3, 0, 0, 0, 3, 3, 3, 3, 3, 3, 0, 0, 3, 3, 3,\n",
       "       3, 3, 3, 3, 3, 0, 0, 3, 3, 0, 3, 0, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,\n",
       "       3, 0, 3, 3, 3, 0, 0, 3, 3, 3, 3, 3, 3, 0, 3, 3, 3, 3, 0, 3, 3, 0,\n",
       "       3, 3, 3, 0, 3, 3, 3, 3, 3, 0, 0, 3, 3, 0, 0, 0, 3, 3, 3, 0, 3, 3,\n",
       "       3, 3, 3, 3, 0, 3, 3, 3, 3, 3, 3, 3, 0, 3, 3, 3, 3, 0, 3, 3, 3, 3,\n",
       "       3, 3, 3, 0, 0, 0, 3, 0, 3, 3, 3, 0, 3, 3, 3, 3, 3, 0, 3, 0, 3, 3,\n",
       "       3, 3, 0, 3, 3, 3, 0, 3, 0, 0, 0, 3, 3, 3, 3, 3, 3, 0, 3, 3, 3, 3,\n",
       "       3, 0, 3, 0, 3, 3, 3, 3, 3, 3, 0, 3, 0, 0, 3, 3, 0, 3, 0, 0, 3, 3,\n",
       "       3, 0, 3, 3, 3, 3, 0, 0, 3, 3, 3, 3, 0, 3, 3, 3, 3, 0, 3, 3, 0, 3,\n",
       "       0, 0, 3, 3, 3, 3, 3, 3, 3, 0, 3, 3, 3, 3, 3, 3, 3, 0, 3, 3, 0, 3,\n",
       "       3, 0, 3, 0, 3, 3, 0, 3, 3, 3, 0, 3, 3, 3, 3, 0, 3, 3, 0, 3, 3, 3,\n",
       "       3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 0, 0, 3, 3, 3, 3, 0, 3, 0, 3, 3, 3,\n",
       "       3, 0, 3, 3, 0, 3, 3, 3, 0, 3, 0, 3, 3, 3, 0, 3, 3, 0, 0, 3, 3, 3,\n",
       "       0, 0, 0, 3, 3, 3, 0, 3, 3, 3, 0, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 0,\n",
       "       3, 3, 3, 0, 3, 3, 3, 3, 3, 0, 0, 3, 3, 0, 3, 3, 3, 3, 3, 3, 0, 3,\n",
       "       3, 3, 3, 3, 3, 3, 0, 0, 3, 3, 3, 0, 3, 3, 3, 3, 0, 3, 3, 3, 3, 3,\n",
       "       0, 3, 0, 0, 3, 3, 3, 3, 3, 0, 3, 3, 3, 3, 3, 3, 3, 0, 3, 3, 3, 3,\n",
       "       3, 0, 0, 0])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds = np.argmax(test_preds.predictions, axis=-1)\n",
    "preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "0600ff95-8e9b-4dbb-9778-68b96e80053e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['hap',\n",
       " 'neu',\n",
       " 'sad',\n",
       " 'hap',\n",
       " 'sad',\n",
       " 'neu',\n",
       " 'neu',\n",
       " 'hap',\n",
       " 'sad',\n",
       " 'neu',\n",
       " 'hap',\n",
       " 'neu',\n",
       " 'ang',\n",
       " 'sad',\n",
       " 'neu',\n",
       " 'sad',\n",
       " 'ang',\n",
       " 'neu',\n",
       " 'hap',\n",
       " 'hap',\n",
       " 'sad',\n",
       " 'hap',\n",
       " 'ang',\n",
       " 'sad',\n",
       " 'sad',\n",
       " 'sad',\n",
       " 'ang',\n",
       " 'sad',\n",
       " 'ang',\n",
       " 'neu',\n",
       " 'hap',\n",
       " 'hap',\n",
       " 'neu',\n",
       " 'hap',\n",
       " 'hap',\n",
       " 'neu',\n",
       " 'neu',\n",
       " 'neu',\n",
       " 'hap',\n",
       " 'hap',\n",
       " 'neu',\n",
       " 'neu',\n",
       " 'ang',\n",
       " 'neu',\n",
       " 'neu',\n",
       " 'ang',\n",
       " 'neu',\n",
       " 'neu',\n",
       " 'hap',\n",
       " 'sad',\n",
       " 'neu',\n",
       " 'sad',\n",
       " 'neu',\n",
       " 'neu',\n",
       " 'sad',\n",
       " 'hap',\n",
       " 'ang',\n",
       " 'neu',\n",
       " 'sad',\n",
       " 'neu',\n",
       " 'ang',\n",
       " 'neu',\n",
       " 'hap',\n",
       " 'ang',\n",
       " 'hap',\n",
       " 'neu',\n",
       " 'sad',\n",
       " 'sad',\n",
       " 'hap',\n",
       " 'hap',\n",
       " 'ang',\n",
       " 'hap',\n",
       " 'neu',\n",
       " 'sad',\n",
       " 'neu',\n",
       " 'neu',\n",
       " 'hap',\n",
       " 'neu',\n",
       " 'sad',\n",
       " 'neu',\n",
       " 'sad',\n",
       " 'neu',\n",
       " 'neu',\n",
       " 'ang',\n",
       " 'sad',\n",
       " 'hap',\n",
       " 'ang',\n",
       " 'hap',\n",
       " 'neu',\n",
       " 'ang',\n",
       " 'hap',\n",
       " 'sad',\n",
       " 'ang',\n",
       " 'sad',\n",
       " 'neu',\n",
       " 'sad',\n",
       " 'neu',\n",
       " 'ang',\n",
       " 'neu',\n",
       " 'ang',\n",
       " 'ang',\n",
       " 'neu',\n",
       " 'neu',\n",
       " 'hap',\n",
       " 'hap',\n",
       " 'ang',\n",
       " 'hap',\n",
       " 'hap',\n",
       " 'hap',\n",
       " 'neu',\n",
       " 'hap',\n",
       " 'sad',\n",
       " 'neu',\n",
       " 'hap',\n",
       " 'hap',\n",
       " 'hap',\n",
       " 'neu',\n",
       " 'hap',\n",
       " 'neu',\n",
       " 'sad',\n",
       " 'hap',\n",
       " 'sad',\n",
       " 'sad',\n",
       " 'hap',\n",
       " 'neu',\n",
       " 'ang',\n",
       " 'neu',\n",
       " 'hap',\n",
       " 'neu',\n",
       " 'hap',\n",
       " 'neu',\n",
       " 'neu',\n",
       " 'neu',\n",
       " 'neu',\n",
       " 'sad',\n",
       " 'hap',\n",
       " 'ang',\n",
       " 'sad',\n",
       " 'neu',\n",
       " 'ang',\n",
       " 'neu',\n",
       " 'hap',\n",
       " 'hap',\n",
       " 'sad',\n",
       " 'neu',\n",
       " 'ang',\n",
       " 'hap',\n",
       " 'hap',\n",
       " 'hap',\n",
       " 'neu',\n",
       " 'neu',\n",
       " 'hap',\n",
       " 'sad',\n",
       " 'sad',\n",
       " 'neu',\n",
       " 'hap',\n",
       " 'ang',\n",
       " 'neu',\n",
       " 'ang',\n",
       " 'hap',\n",
       " 'hap',\n",
       " 'neu',\n",
       " 'neu',\n",
       " 'sad',\n",
       " 'hap',\n",
       " 'hap',\n",
       " 'sad',\n",
       " 'hap',\n",
       " 'neu',\n",
       " 'hap',\n",
       " 'neu',\n",
       " 'ang',\n",
       " 'hap',\n",
       " 'ang',\n",
       " 'ang',\n",
       " 'hap',\n",
       " 'neu',\n",
       " 'sad',\n",
       " 'ang',\n",
       " 'sad',\n",
       " 'ang',\n",
       " 'neu',\n",
       " 'neu',\n",
       " 'sad',\n",
       " 'hap',\n",
       " 'hap',\n",
       " 'neu',\n",
       " 'ang',\n",
       " 'sad',\n",
       " 'ang',\n",
       " 'neu',\n",
       " 'neu',\n",
       " 'neu',\n",
       " 'hap',\n",
       " 'sad',\n",
       " 'sad',\n",
       " 'hap',\n",
       " 'ang',\n",
       " 'neu',\n",
       " 'sad',\n",
       " 'hap',\n",
       " 'hap',\n",
       " 'hap',\n",
       " 'ang',\n",
       " 'hap',\n",
       " 'hap',\n",
       " 'hap',\n",
       " 'hap',\n",
       " 'neu',\n",
       " 'neu',\n",
       " 'sad',\n",
       " 'hap',\n",
       " 'ang',\n",
       " 'neu',\n",
       " 'hap',\n",
       " 'neu',\n",
       " 'hap',\n",
       " 'ang',\n",
       " 'hap',\n",
       " 'hap',\n",
       " 'neu',\n",
       " 'hap',\n",
       " 'sad',\n",
       " 'sad',\n",
       " 'neu',\n",
       " 'neu',\n",
       " 'neu',\n",
       " 'hap',\n",
       " 'hap',\n",
       " 'ang',\n",
       " 'hap',\n",
       " 'sad',\n",
       " 'neu',\n",
       " 'neu',\n",
       " 'neu',\n",
       " 'hap',\n",
       " 'sad',\n",
       " 'sad',\n",
       " 'sad',\n",
       " 'ang',\n",
       " 'hap',\n",
       " 'hap',\n",
       " 'hap',\n",
       " 'sad',\n",
       " 'neu',\n",
       " 'ang',\n",
       " 'neu',\n",
       " 'hap',\n",
       " 'ang',\n",
       " 'neu',\n",
       " 'ang',\n",
       " 'ang',\n",
       " 'hap',\n",
       " 'sad',\n",
       " 'sad',\n",
       " 'hap',\n",
       " 'sad',\n",
       " 'ang',\n",
       " 'hap',\n",
       " 'ang',\n",
       " 'neu',\n",
       " 'hap',\n",
       " 'ang',\n",
       " 'neu',\n",
       " 'hap',\n",
       " 'hap',\n",
       " 'neu',\n",
       " 'neu',\n",
       " 'sad',\n",
       " 'ang',\n",
       " 'neu',\n",
       " 'ang',\n",
       " 'hap',\n",
       " 'hap',\n",
       " 'ang',\n",
       " 'sad',\n",
       " 'sad',\n",
       " 'neu',\n",
       " 'sad',\n",
       " 'ang',\n",
       " 'ang',\n",
       " 'sad',\n",
       " 'neu',\n",
       " 'neu',\n",
       " 'neu',\n",
       " 'sad',\n",
       " 'neu',\n",
       " 'hap',\n",
       " 'hap',\n",
       " 'sad',\n",
       " 'hap',\n",
       " 'neu',\n",
       " 'hap',\n",
       " 'hap',\n",
       " 'hap',\n",
       " 'hap',\n",
       " 'ang',\n",
       " 'ang',\n",
       " 'hap',\n",
       " 'neu',\n",
       " 'hap',\n",
       " 'hap',\n",
       " 'hap',\n",
       " 'hap',\n",
       " 'sad',\n",
       " 'neu',\n",
       " 'neu',\n",
       " 'sad',\n",
       " 'hap',\n",
       " 'hap',\n",
       " 'ang',\n",
       " 'neu',\n",
       " 'sad',\n",
       " 'sad',\n",
       " 'neu',\n",
       " 'neu',\n",
       " 'neu',\n",
       " 'neu',\n",
       " 'hap',\n",
       " 'ang',\n",
       " 'neu',\n",
       " 'hap',\n",
       " 'ang',\n",
       " 'hap',\n",
       " 'neu',\n",
       " 'sad',\n",
       " 'neu',\n",
       " 'ang',\n",
       " 'hap',\n",
       " 'neu',\n",
       " 'sad',\n",
       " 'sad',\n",
       " 'hap',\n",
       " 'hap',\n",
       " 'neu',\n",
       " 'ang',\n",
       " 'hap',\n",
       " 'neu',\n",
       " 'hap',\n",
       " 'ang',\n",
       " 'neu',\n",
       " 'ang',\n",
       " 'neu',\n",
       " 'hap',\n",
       " 'hap',\n",
       " 'neu',\n",
       " 'ang',\n",
       " 'neu',\n",
       " 'neu',\n",
       " 'neu',\n",
       " 'hap',\n",
       " 'hap',\n",
       " 'ang',\n",
       " 'neu',\n",
       " 'ang',\n",
       " 'neu',\n",
       " 'sad',\n",
       " 'hap',\n",
       " 'neu',\n",
       " 'neu',\n",
       " 'hap',\n",
       " 'neu',\n",
       " 'hap',\n",
       " 'sad',\n",
       " 'sad',\n",
       " 'sad',\n",
       " 'ang',\n",
       " 'neu',\n",
       " 'neu',\n",
       " 'sad',\n",
       " 'ang',\n",
       " 'neu',\n",
       " 'hap',\n",
       " 'ang',\n",
       " 'hap',\n",
       " 'neu',\n",
       " 'sad',\n",
       " 'sad',\n",
       " 'neu',\n",
       " 'neu',\n",
       " 'hap',\n",
       " 'ang',\n",
       " 'sad',\n",
       " 'ang',\n",
       " 'hap',\n",
       " 'sad',\n",
       " 'hap',\n",
       " 'sad',\n",
       " 'sad',\n",
       " 'ang',\n",
       " 'sad',\n",
       " 'hap',\n",
       " 'hap',\n",
       " 'hap',\n",
       " 'ang',\n",
       " 'hap',\n",
       " 'ang',\n",
       " 'sad',\n",
       " 'hap',\n",
       " 'ang',\n",
       " 'sad',\n",
       " 'sad',\n",
       " 'sad',\n",
       " 'sad',\n",
       " 'neu',\n",
       " 'ang',\n",
       " 'ang',\n",
       " 'neu',\n",
       " 'neu',\n",
       " 'hap',\n",
       " 'neu',\n",
       " 'hap',\n",
       " 'sad',\n",
       " 'ang',\n",
       " 'neu',\n",
       " 'hap',\n",
       " 'hap',\n",
       " 'ang',\n",
       " 'hap',\n",
       " 'hap',\n",
       " 'hap',\n",
       " 'neu',\n",
       " 'ang',\n",
       " 'hap',\n",
       " 'ang',\n",
       " 'neu',\n",
       " 'ang',\n",
       " 'sad',\n",
       " 'sad',\n",
       " 'neu',\n",
       " 'neu',\n",
       " 'neu',\n",
       " 'hap',\n",
       " 'sad',\n",
       " 'sad',\n",
       " 'sad',\n",
       " 'ang',\n",
       " 'ang',\n",
       " 'neu',\n",
       " 'ang',\n",
       " 'sad',\n",
       " 'hap',\n",
       " 'neu',\n",
       " 'hap',\n",
       " 'hap',\n",
       " 'hap',\n",
       " 'neu',\n",
       " 'sad',\n",
       " 'ang',\n",
       " 'hap',\n",
       " 'neu',\n",
       " 'neu',\n",
       " 'hap',\n",
       " 'ang',\n",
       " 'ang',\n",
       " 'neu',\n",
       " 'neu',\n",
       " 'neu',\n",
       " 'neu',\n",
       " 'sad',\n",
       " 'neu',\n",
       " 'neu',\n",
       " 'neu',\n",
       " 'sad',\n",
       " 'neu',\n",
       " 'sad',\n",
       " 'hap',\n",
       " 'neu',\n",
       " 'neu',\n",
       " 'sad',\n",
       " 'neu',\n",
       " 'hap',\n",
       " 'sad',\n",
       " 'neu',\n",
       " 'hap',\n",
       " 'ang',\n",
       " 'neu',\n",
       " 'neu',\n",
       " 'neu',\n",
       " 'hap',\n",
       " 'neu',\n",
       " 'hap',\n",
       " 'neu',\n",
       " 'hap',\n",
       " 'neu',\n",
       " 'neu',\n",
       " 'hap',\n",
       " 'hap',\n",
       " 'hap',\n",
       " 'neu',\n",
       " 'ang',\n",
       " 'hap',\n",
       " 'ang',\n",
       " 'hap',\n",
       " 'sad',\n",
       " 'hap',\n",
       " 'ang',\n",
       " 'sad',\n",
       " 'ang',\n",
       " 'sad',\n",
       " 'sad',\n",
       " 'hap',\n",
       " 'ang',\n",
       " 'sad',\n",
       " 'hap',\n",
       " 'hap',\n",
       " 'ang',\n",
       " 'sad',\n",
       " 'neu',\n",
       " 'sad',\n",
       " 'sad',\n",
       " 'hap',\n",
       " 'neu',\n",
       " 'ang',\n",
       " 'hap',\n",
       " 'hap',\n",
       " 'neu',\n",
       " 'hap',\n",
       " 'ang',\n",
       " 'sad',\n",
       " 'hap',\n",
       " 'sad',\n",
       " 'ang',\n",
       " 'hap',\n",
       " 'hap',\n",
       " 'neu',\n",
       " 'neu',\n",
       " 'ang',\n",
       " 'hap',\n",
       " 'neu',\n",
       " 'sad',\n",
       " 'hap',\n",
       " 'hap',\n",
       " 'neu',\n",
       " 'hap',\n",
       " 'ang',\n",
       " 'ang',\n",
       " 'hap',\n",
       " 'ang',\n",
       " 'hap',\n",
       " 'hap',\n",
       " 'hap',\n",
       " 'neu',\n",
       " 'hap',\n",
       " 'sad',\n",
       " 'neu',\n",
       " 'hap',\n",
       " 'hap',\n",
       " 'hap',\n",
       " 'sad',\n",
       " 'hap',\n",
       " 'neu',\n",
       " 'sad',\n",
       " 'hap']"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "id2label_fn(test_preds.label_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "c4246128-7715-400b-a5da-6ec4597ee43d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Thank you</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Uh huh. I didn't come here get in yelling matc...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>I got this idea watching them go down. Everyth...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Charles. That was his name. He did wriggle so ...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>I can't be that strong. A whole year.</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   0  1\n",
       "0                                          Thank you  3\n",
       "1  Uh huh. I didn't come here get in yelling matc...  0\n",
       "2  I got this idea watching them go down. Everyth...  0\n",
       "3  Charles. That was his name. He did wriggle so ...  3\n",
       "4              I can't be that strong. A whole year.  3"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df = pd.DataFrame(list(zip(tokenized_datasets[\"test\"][\"text\"], preds)))\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "3a3d43d2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "da75d8512fd5439288d682b038ad075b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       ".DS_Store:   0%|          | 0.00/10.2k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "64c1e3aaca2d491eaa8ce1c98ab39e09",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/268M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a18ef3777f9a48179fd7439103069b01",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "events.out.tfevents.1710916704.Meghanadhs-MacBook-Pro-2.local.98982.0:   0%|          | 0.00/690 [00:00<?, ?B/â€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "44c2a71bcc97449cb79ce55c096c4fc2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "training_args.bin:   0%|          | 0.00/4.98k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1fce72b0e5e04463a2bb40008459f24c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Upload 4 LFS files:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "CommitInfo(commit_url='https://huggingface.co/meghanadh/finetune_bert_iemocap_text/commit/107a0fe11f551ee8b721b1d81e8d49c103ba8eff', commit_message='End of training', commit_description='', oid='107a0fe11f551ee8b721b1d81e8d49c103ba8eff', pr_url=None, pr_revision=None, pr_num=None)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.push_to_hub()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "a6e04bc8-de9e-4094-9ab2-7b28bec18414",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8eab517a2a574bfb89c0350670965fc5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/783 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8c1b8b2679994da78399e02dfe3d8f57",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/268M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "26cc49a902ed4eb7baa896a330341766",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/1.20k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Use a pipeline as a high-level helper\n",
    "from transformers import pipeline\n",
    "\n",
    "hub_model = pipeline(\"text-classification\", model=\"meghanadh/finetune_bert_iemocap_text\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "835a0144-8713-47f8-8c6c-286d6649bcc2",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'inp'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[23], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m tokenized_datasets[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtest\u001b[39m\u001b[38;5;124m\"\u001b[39m][\u001b[38;5;241m0\u001b[39m][\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124minp\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n",
      "\u001b[0;31mKeyError\u001b[0m: 'inp'"
     ]
    }
   ],
   "source": [
    "tokenized_datasets[\"test\"][0][\"inp\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "4c1aafca-ed88-48b7-aca8-275de79af632",
   "metadata": {},
   "outputs": [],
   "source": [
    "dd = hub_model(tokenized_datasets[\"test\"][\"text\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "c651e84d-5838-4b74-910c-a14e8a231db8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'label': 'ang', 'score': 0.2622804045677185},\n",
       " {'label': 'ang', 'score': 0.27050065994262695},\n",
       " {'label': 'ang', 'score': 0.27191266417503357},\n",
       " {'label': 'ang', 'score': 0.26439133286476135},\n",
       " {'label': 'ang', 'score': 0.2613983750343323},\n",
       " {'label': 'sad', 'score': 0.2626360058784485},\n",
       " {'label': 'ang', 'score': 0.2643706798553467},\n",
       " {'label': 'ang', 'score': 0.26567575335502625},\n",
       " {'label': 'ang', 'score': 0.2673676908016205},\n",
       " {'label': 'ang', 'score': 0.2669679820537567},\n",
       " {'label': 'ang', 'score': 0.26372230052948},\n",
       " {'label': 'ang', 'score': 0.2647041976451874},\n",
       " {'label': 'ang', 'score': 0.26163816452026367},\n",
       " {'label': 'ang', 'score': 0.2686363756656647},\n",
       " {'label': 'ang', 'score': 0.27395957708358765},\n",
       " {'label': 'ang', 'score': 0.2717868387699127},\n",
       " {'label': 'ang', 'score': 0.2636277675628662},\n",
       " {'label': 'ang', 'score': 0.26871436834335327},\n",
       " {'label': 'ang', 'score': 0.2615692913532257},\n",
       " {'label': 'sad', 'score': 0.2707075774669647},\n",
       " {'label': 'ang', 'score': 0.25808700919151306},\n",
       " {'label': 'ang', 'score': 0.2638348937034607},\n",
       " {'label': 'sad', 'score': 0.2613615393638611},\n",
       " {'label': 'ang', 'score': 0.2718959152698517},\n",
       " {'label': 'ang', 'score': 0.2631029486656189},\n",
       " {'label': 'ang', 'score': 0.2646326422691345},\n",
       " {'label': 'ang', 'score': 0.27318379282951355},\n",
       " {'label': 'ang', 'score': 0.26807263493537903},\n",
       " {'label': 'ang', 'score': 0.2645745277404785},\n",
       " {'label': 'ang', 'score': 0.2650253176689148},\n",
       " {'label': 'sad', 'score': 0.26434484124183655},\n",
       " {'label': 'sad', 'score': 0.2672334313392639},\n",
       " {'label': 'ang', 'score': 0.2633656859397888},\n",
       " {'label': 'sad', 'score': 0.2684886157512665},\n",
       " {'label': 'ang', 'score': 0.2692772150039673},\n",
       " {'label': 'ang', 'score': 0.26948463916778564},\n",
       " {'label': 'ang', 'score': 0.2671735882759094},\n",
       " {'label': 'sad', 'score': 0.2686839699745178},\n",
       " {'label': 'ang', 'score': 0.26202645897865295},\n",
       " {'label': 'ang', 'score': 0.26685547828674316},\n",
       " {'label': 'ang', 'score': 0.26126599311828613},\n",
       " {'label': 'ang', 'score': 0.2802877128124237},\n",
       " {'label': 'ang', 'score': 0.26290082931518555},\n",
       " {'label': 'ang', 'score': 0.25916263461112976},\n",
       " {'label': 'ang', 'score': 0.27056053280830383},\n",
       " {'label': 'ang', 'score': 0.26180538535118103},\n",
       " {'label': 'ang', 'score': 0.2680962085723877},\n",
       " {'label': 'sad', 'score': 0.26358163356781006},\n",
       " {'label': 'sad', 'score': 0.2711401581764221},\n",
       " {'label': 'ang', 'score': 0.26415780186653137},\n",
       " {'label': 'ang', 'score': 0.26412567496299744},\n",
       " {'label': 'ang', 'score': 0.2718782126903534},\n",
       " {'label': 'sad', 'score': 0.2823275625705719},\n",
       " {'label': 'ang', 'score': 0.2678850591182709},\n",
       " {'label': 'ang', 'score': 0.2670444846153259},\n",
       " {'label': 'ang', 'score': 0.2617930471897125},\n",
       " {'label': 'ang', 'score': 0.26417043805122375},\n",
       " {'label': 'ang', 'score': 0.26791512966156006},\n",
       " {'label': 'ang', 'score': 0.2666434049606323},\n",
       " {'label': 'sad', 'score': 0.27529269456863403},\n",
       " {'label': 'hap', 'score': 0.2609313428401947},\n",
       " {'label': 'sad', 'score': 0.2728691101074219},\n",
       " {'label': 'ang', 'score': 0.26695218682289124},\n",
       " {'label': 'sad', 'score': 0.2675687074661255},\n",
       " {'label': 'ang', 'score': 0.27632588148117065},\n",
       " {'label': 'ang', 'score': 0.2624841034412384},\n",
       " {'label': 'sad', 'score': 0.26304447650909424},\n",
       " {'label': 'sad', 'score': 0.26356273889541626},\n",
       " {'label': 'ang', 'score': 0.26545020937919617},\n",
       " {'label': 'ang', 'score': 0.2630637586116791},\n",
       " {'label': 'ang', 'score': 0.26959937810897827},\n",
       " {'label': 'ang', 'score': 0.2659875452518463},\n",
       " {'label': 'sad', 'score': 0.2656609117984772},\n",
       " {'label': 'ang', 'score': 0.2624841034412384},\n",
       " {'label': 'ang', 'score': 0.26462650299072266},\n",
       " {'label': 'ang', 'score': 0.2700525224208832},\n",
       " {'label': 'sad', 'score': 0.2604432702064514},\n",
       " {'label': 'sad', 'score': 0.2637655735015869},\n",
       " {'label': 'ang', 'score': 0.2659105956554413},\n",
       " {'label': 'ang', 'score': 0.2624841034412384},\n",
       " {'label': 'ang', 'score': 0.27479493618011475},\n",
       " {'label': 'ang', 'score': 0.26836109161376953},\n",
       " {'label': 'ang', 'score': 0.2618925869464874},\n",
       " {'label': 'sad', 'score': 0.2675687074661255},\n",
       " {'label': 'ang', 'score': 0.26803281903266907},\n",
       " {'label': 'ang', 'score': 0.26950857043266296},\n",
       " {'label': 'ang', 'score': 0.26625242829322815},\n",
       " {'label': 'sad', 'score': 0.26439711451530457},\n",
       " {'label': 'ang', 'score': 0.26403290033340454},\n",
       " {'label': 'ang', 'score': 0.2654862701892853},\n",
       " {'label': 'sad', 'score': 0.2638172209262848},\n",
       " {'label': 'ang', 'score': 0.26636838912963867},\n",
       " {'label': 'sad', 'score': 0.26575013995170593},\n",
       " {'label': 'ang', 'score': 0.2624841034412384},\n",
       " {'label': 'ang', 'score': 0.2736433148384094},\n",
       " {'label': 'sad', 'score': 0.26485827565193176},\n",
       " {'label': 'sad', 'score': 0.2589990198612213},\n",
       " {'label': 'ang', 'score': 0.2633383572101593},\n",
       " {'label': 'ang', 'score': 0.27755773067474365},\n",
       " {'label': 'sad', 'score': 0.2634640336036682},\n",
       " {'label': 'sad', 'score': 0.2646966576576233},\n",
       " {'label': 'ang', 'score': 0.2728005051612854},\n",
       " {'label': 'sad', 'score': 0.2624404728412628},\n",
       " {'label': 'ang', 'score': 0.2670559287071228},\n",
       " {'label': 'ang', 'score': 0.26529237627983093},\n",
       " {'label': 'ang', 'score': 0.26615458726882935},\n",
       " {'label': 'ang', 'score': 0.26628828048706055},\n",
       " {'label': 'ang', 'score': 0.2724616527557373},\n",
       " {'label': 'sad', 'score': 0.2635575532913208},\n",
       " {'label': 'ang', 'score': 0.2802625596523285},\n",
       " {'label': 'sad', 'score': 0.2721337080001831},\n",
       " {'label': 'ang', 'score': 0.26705315709114075},\n",
       " {'label': 'ang', 'score': 0.2659650444984436},\n",
       " {'label': 'ang', 'score': 0.27435293793678284},\n",
       " {'label': 'ang', 'score': 0.2624841034412384},\n",
       " {'label': 'ang', 'score': 0.2691647708415985},\n",
       " {'label': 'ang', 'score': 0.2624841034412384},\n",
       " {'label': 'sad', 'score': 0.26945871114730835},\n",
       " {'label': 'sad', 'score': 0.2672004997730255},\n",
       " {'label': 'ang', 'score': 0.2689180076122284},\n",
       " {'label': 'ang', 'score': 0.2682327926158905},\n",
       " {'label': 'ang', 'score': 0.26848074793815613},\n",
       " {'label': 'ang', 'score': 0.26639291644096375},\n",
       " {'label': 'ang', 'score': 0.2660607397556305},\n",
       " {'label': 'ang', 'score': 0.2654131352901459},\n",
       " {'label': 'ang', 'score': 0.2648574411869049},\n",
       " {'label': 'sad', 'score': 0.2668653130531311},\n",
       " {'label': 'ang', 'score': 0.2622520625591278},\n",
       " {'label': 'ang', 'score': 0.26534783840179443},\n",
       " {'label': 'sad', 'score': 0.2650470733642578},\n",
       " {'label': 'ang', 'score': 0.2682742476463318},\n",
       " {'label': 'ang', 'score': 0.2768835127353668},\n",
       " {'label': 'ang', 'score': 0.27530309557914734},\n",
       " {'label': 'ang', 'score': 0.266453355550766},\n",
       " {'label': 'ang', 'score': 0.26839736104011536},\n",
       " {'label': 'ang', 'score': 0.2669166922569275},\n",
       " {'label': 'ang', 'score': 0.2696182131767273},\n",
       " {'label': 'ang', 'score': 0.2698003649711609},\n",
       " {'label': 'ang', 'score': 0.2718420922756195},\n",
       " {'label': 'ang', 'score': 0.2755042612552643},\n",
       " {'label': 'ang', 'score': 0.26999884843826294},\n",
       " {'label': 'sad', 'score': 0.2642756402492523},\n",
       " {'label': 'ang', 'score': 0.27201923727989197},\n",
       " {'label': 'ang', 'score': 0.26914334297180176},\n",
       " {'label': 'ang', 'score': 0.2624841034412384},\n",
       " {'label': 'sad', 'score': 0.26558858156204224},\n",
       " {'label': 'ang', 'score': 0.26386910676956177},\n",
       " {'label': 'ang', 'score': 0.2658042907714844},\n",
       " {'label': 'ang', 'score': 0.2632629871368408},\n",
       " {'label': 'ang', 'score': 0.2660886347293854},\n",
       " {'label': 'ang', 'score': 0.26949188113212585},\n",
       " {'label': 'ang', 'score': 0.2624841034412384},\n",
       " {'label': 'ang', 'score': 0.26340770721435547},\n",
       " {'label': 'ang', 'score': 0.2640628516674042},\n",
       " {'label': 'ang', 'score': 0.2701681852340698},\n",
       " {'label': 'ang', 'score': 0.2634063959121704},\n",
       " {'label': 'ang', 'score': 0.26738211512565613},\n",
       " {'label': 'ang', 'score': 0.27374276518821716},\n",
       " {'label': 'sad', 'score': 0.2630191445350647},\n",
       " {'label': 'ang', 'score': 0.26017799973487854},\n",
       " {'label': 'ang', 'score': 0.2667405307292938},\n",
       " {'label': 'ang', 'score': 0.2586846947669983},\n",
       " {'label': 'ang', 'score': 0.26570919156074524},\n",
       " {'label': 'ang', 'score': 0.2625923156738281},\n",
       " {'label': 'ang', 'score': 0.26230454444885254},\n",
       " {'label': 'ang', 'score': 0.2615810036659241},\n",
       " {'label': 'ang', 'score': 0.26705315709114075},\n",
       " {'label': 'ang', 'score': 0.26368090510368347},\n",
       " {'label': 'ang', 'score': 0.2727287709712982},\n",
       " {'label': 'ang', 'score': 0.26694774627685547},\n",
       " {'label': 'ang', 'score': 0.2757819592952728},\n",
       " {'label': 'ang', 'score': 0.27209216356277466},\n",
       " {'label': 'sad', 'score': 0.26136472821235657},\n",
       " {'label': 'sad', 'score': 0.2577669620513916},\n",
       " {'label': 'ang', 'score': 0.2612420618534088},\n",
       " {'label': 'sad', 'score': 0.27264466881752014},\n",
       " {'label': 'ang', 'score': 0.2701573967933655},\n",
       " {'label': 'sad', 'score': 0.2619381248950958},\n",
       " {'label': 'sad', 'score': 0.2623446583747864},\n",
       " {'label': 'ang', 'score': 0.2584728002548218},\n",
       " {'label': 'ang', 'score': 0.26881369948387146},\n",
       " {'label': 'ang', 'score': 0.2615281939506531},\n",
       " {'label': 'sad', 'score': 0.2604432702064514},\n",
       " {'label': 'sad', 'score': 0.2614636719226837},\n",
       " {'label': 'ang', 'score': 0.26901835203170776},\n",
       " {'label': 'sad', 'score': 0.2616444230079651},\n",
       " {'label': 'ang', 'score': 0.27132412791252136},\n",
       " {'label': 'sad', 'score': 0.2642224431037903},\n",
       " {'label': 'ang', 'score': 0.2642313241958618},\n",
       " {'label': 'ang', 'score': 0.26287025213241577},\n",
       " {'label': 'ang', 'score': 0.2726438045501709},\n",
       " {'label': 'ang', 'score': 0.26887574791908264},\n",
       " {'label': 'sad', 'score': 0.2674560844898224},\n",
       " {'label': 'ang', 'score': 0.27023154497146606},\n",
       " {'label': 'ang', 'score': 0.26774877309799194},\n",
       " {'label': 'ang', 'score': 0.2658577561378479},\n",
       " {'label': 'ang', 'score': 0.2708016335964203},\n",
       " {'label': 'ang', 'score': 0.2663863003253937},\n",
       " {'label': 'ang', 'score': 0.26028621196746826},\n",
       " {'label': 'ang', 'score': 0.26340770721435547},\n",
       " {'label': 'ang', 'score': 0.26959800720214844},\n",
       " {'label': 'ang', 'score': 0.26566508412361145},\n",
       " {'label': 'ang', 'score': 0.26180437207221985},\n",
       " {'label': 'ang', 'score': 0.27020764350891113},\n",
       " {'label': 'ang', 'score': 0.2677423357963562},\n",
       " {'label': 'sad', 'score': 0.2721157968044281},\n",
       " {'label': 'sad', 'score': 0.2645839750766754},\n",
       " {'label': 'ang', 'score': 0.27212443947792053},\n",
       " {'label': 'sad', 'score': 0.2638689875602722},\n",
       " {'label': 'ang', 'score': 0.2644330859184265},\n",
       " {'label': 'ang', 'score': 0.2634265720844269},\n",
       " {'label': 'ang', 'score': 0.2737560570240021},\n",
       " {'label': 'sad', 'score': 0.26471805572509766},\n",
       " {'label': 'ang', 'score': 0.27400562167167664},\n",
       " {'label': 'ang', 'score': 0.2676245868206024},\n",
       " {'label': 'ang', 'score': 0.26530638337135315},\n",
       " {'label': 'ang', 'score': 0.26774924993515015},\n",
       " {'label': 'sad', 'score': 0.2699413001537323},\n",
       " {'label': 'sad', 'score': 0.2640303373336792},\n",
       " {'label': 'ang', 'score': 0.2665540277957916},\n",
       " {'label': 'ang', 'score': 0.2671782672405243},\n",
       " {'label': 'ang', 'score': 0.2719506323337555},\n",
       " {'label': 'sad', 'score': 0.2570863962173462},\n",
       " {'label': 'ang', 'score': 0.26571744680404663},\n",
       " {'label': 'ang', 'score': 0.26750561594963074},\n",
       " {'label': 'ang', 'score': 0.26523464918136597},\n",
       " {'label': 'ang', 'score': 0.2763572335243225},\n",
       " {'label': 'ang', 'score': 0.26834720373153687},\n",
       " {'label': 'ang', 'score': 0.26768019795417786},\n",
       " {'label': 'sad', 'score': 0.2595612704753876},\n",
       " {'label': 'ang', 'score': 0.2619742751121521},\n",
       " {'label': 'ang', 'score': 0.26233989000320435},\n",
       " {'label': 'sad', 'score': 0.2610950171947479},\n",
       " {'label': 'ang', 'score': 0.2697763442993164},\n",
       " {'label': 'sad', 'score': 0.26605701446533203},\n",
       " {'label': 'sad', 'score': 0.2780974507331848},\n",
       " {'label': 'ang', 'score': 0.26340770721435547},\n",
       " {'label': 'ang', 'score': 0.2619117200374603},\n",
       " {'label': 'ang', 'score': 0.26491662859916687},\n",
       " {'label': 'ang', 'score': 0.2709273397922516},\n",
       " {'label': 'ang', 'score': 0.2654847204685211},\n",
       " {'label': 'ang', 'score': 0.2686211168766022},\n",
       " {'label': 'ang', 'score': 0.2663783133029938},\n",
       " {'label': 'ang', 'score': 0.2606452405452728},\n",
       " {'label': 'sad', 'score': 0.26314759254455566},\n",
       " {'label': 'ang', 'score': 0.2658267617225647},\n",
       " {'label': 'sad', 'score': 0.2795073091983795},\n",
       " {'label': 'ang', 'score': 0.26387691497802734},\n",
       " {'label': 'sad', 'score': 0.2689603567123413},\n",
       " {'label': 'ang', 'score': 0.2696366608142853},\n",
       " {'label': 'sad', 'score': 0.26558858156204224},\n",
       " {'label': 'ang', 'score': 0.2707611918449402},\n",
       " {'label': 'ang', 'score': 0.2698816657066345},\n",
       " {'label': 'ang', 'score': 0.2637771666049957},\n",
       " {'label': 'sad', 'score': 0.25804856419563293},\n",
       " {'label': 'ang', 'score': 0.2687009572982788},\n",
       " {'label': 'ang', 'score': 0.2677892744541168},\n",
       " {'label': 'ang', 'score': 0.2708296477794647},\n",
       " {'label': 'ang', 'score': 0.2692522704601288},\n",
       " {'label': 'sad', 'score': 0.2657400071620941},\n",
       " {'label': 'sad', 'score': 0.2667993903160095},\n",
       " {'label': 'ang', 'score': 0.2634451985359192},\n",
       " {'label': 'ang', 'score': 0.2632189393043518},\n",
       " {'label': 'sad', 'score': 0.2724169194698334},\n",
       " {'label': 'ang', 'score': 0.2691127359867096},\n",
       " {'label': 'sad', 'score': 0.2690901756286621},\n",
       " {'label': 'sad', 'score': 0.2660655975341797},\n",
       " {'label': 'ang', 'score': 0.26170963048934937},\n",
       " {'label': 'ang', 'score': 0.2749866545200348},\n",
       " {'label': 'sad', 'score': 0.2701907157897949},\n",
       " {'label': 'ang', 'score': 0.26980826258659363},\n",
       " {'label': 'sad', 'score': 0.2660946846008301},\n",
       " {'label': 'ang', 'score': 0.2604033946990967},\n",
       " {'label': 'ang', 'score': 0.2684171795845032},\n",
       " {'label': 'ang', 'score': 0.2653365433216095},\n",
       " {'label': 'ang', 'score': 0.2674127221107483},\n",
       " {'label': 'ang', 'score': 0.26731792092323303},\n",
       " {'label': 'ang', 'score': 0.26275625824928284},\n",
       " {'label': 'sad', 'score': 0.2756219804286957},\n",
       " {'label': 'sad', 'score': 0.2637413442134857},\n",
       " {'label': 'ang', 'score': 0.2627008259296417},\n",
       " {'label': 'ang', 'score': 0.2755186855792999},\n",
       " {'label': 'ang', 'score': 0.26306816935539246},\n",
       " {'label': 'ang', 'score': 0.26705747842788696},\n",
       " {'label': 'sad', 'score': 0.26430514454841614},\n",
       " {'label': 'sad', 'score': 0.2683626711368561},\n",
       " {'label': 'ang', 'score': 0.26764336228370667},\n",
       " {'label': 'sad', 'score': 0.26323410868644714},\n",
       " {'label': 'sad', 'score': 0.27120333909988403},\n",
       " {'label': 'ang', 'score': 0.26176080107688904},\n",
       " {'label': 'ang', 'score': 0.2700164020061493},\n",
       " {'label': 'ang', 'score': 0.27149972319602966},\n",
       " {'label': 'ang', 'score': 0.26076385378837585},\n",
       " {'label': 'ang', 'score': 0.2719244062900543},\n",
       " {'label': 'ang', 'score': 0.26561880111694336},\n",
       " {'label': 'ang', 'score': 0.2589597702026367},\n",
       " {'label': 'ang', 'score': 0.2697729766368866},\n",
       " {'label': 'ang', 'score': 0.2636406421661377},\n",
       " {'label': 'ang', 'score': 0.2646356225013733},\n",
       " {'label': 'ang', 'score': 0.2624841034412384},\n",
       " {'label': 'ang', 'score': 0.26334482431411743},\n",
       " {'label': 'sad', 'score': 0.264187216758728},\n",
       " {'label': 'ang', 'score': 0.26434069871902466},\n",
       " {'label': 'ang', 'score': 0.26914575695991516},\n",
       " {'label': 'ang', 'score': 0.27187681198120117},\n",
       " {'label': 'ang', 'score': 0.2737409174442291},\n",
       " {'label': 'ang', 'score': 0.26442766189575195},\n",
       " {'label': 'ang', 'score': 0.2652398645877838},\n",
       " {'label': 'ang', 'score': 0.26163920760154724},\n",
       " {'label': 'sad', 'score': 0.2664030194282532},\n",
       " {'label': 'ang', 'score': 0.2737802565097809},\n",
       " {'label': 'ang', 'score': 0.263306587934494},\n",
       " {'label': 'ang', 'score': 0.2622607350349426},\n",
       " {'label': 'ang', 'score': 0.2623828053474426},\n",
       " {'label': 'ang', 'score': 0.268505334854126},\n",
       " {'label': 'ang', 'score': 0.2683565616607666},\n",
       " {'label': 'ang', 'score': 0.26830294728279114},\n",
       " {'label': 'ang', 'score': 0.26622432470321655},\n",
       " {'label': 'ang', 'score': 0.26698794960975647},\n",
       " {'label': 'ang', 'score': 0.26950356364250183},\n",
       " {'label': 'sad', 'score': 0.2695308029651642},\n",
       " {'label': 'sad', 'score': 0.26490673422813416},\n",
       " {'label': 'ang', 'score': 0.2670716643333435},\n",
       " {'label': 'ang', 'score': 0.2621963322162628},\n",
       " {'label': 'sad', 'score': 0.26209041476249695},\n",
       " {'label': 'ang', 'score': 0.2652296721935272},\n",
       " {'label': 'sad', 'score': 0.25889211893081665},\n",
       " {'label': 'ang', 'score': 0.2635386884212494},\n",
       " {'label': 'sad', 'score': 0.26694685220718384},\n",
       " {'label': 'ang', 'score': 0.2624841034412384},\n",
       " {'label': 'ang', 'score': 0.2720203697681427},\n",
       " {'label': 'ang', 'score': 0.2761193513870239},\n",
       " {'label': 'sad', 'score': 0.2630006968975067},\n",
       " {'label': 'sad', 'score': 0.264358252286911},\n",
       " {'label': 'sad', 'score': 0.26358163356781006},\n",
       " {'label': 'ang', 'score': 0.26550552248954773},\n",
       " {'label': 'ang', 'score': 0.2624841034412384},\n",
       " {'label': 'ang', 'score': 0.2620282471179962},\n",
       " {'label': 'ang', 'score': 0.2628059983253479},\n",
       " {'label': 'sad', 'score': 0.27691665291786194},\n",
       " {'label': 'ang', 'score': 0.27733153104782104},\n",
       " {'label': 'sad', 'score': 0.26272279024124146},\n",
       " {'label': 'ang', 'score': 0.2695105969905853},\n",
       " {'label': 'ang', 'score': 0.26645591855049133},\n",
       " {'label': 'sad', 'score': 0.25952282547950745},\n",
       " {'label': 'ang', 'score': 0.266453355550766},\n",
       " {'label': 'ang', 'score': 0.2721194326877594},\n",
       " {'label': 'ang', 'score': 0.26714542508125305},\n",
       " {'label': 'ang', 'score': 0.26705315709114075},\n",
       " {'label': 'ang', 'score': 0.2748233675956726},\n",
       " {'label': 'sad', 'score': 0.26531681418418884},\n",
       " {'label': 'sad', 'score': 0.2645699977874756},\n",
       " {'label': 'ang', 'score': 0.2644980549812317},\n",
       " {'label': 'ang', 'score': 0.26803281903266907},\n",
       " {'label': 'sad', 'score': 0.2682332694530487},\n",
       " {'label': 'ang', 'score': 0.26809921860694885},\n",
       " {'label': 'ang', 'score': 0.2625509798526764},\n",
       " {'label': 'sad', 'score': 0.2629624009132385},\n",
       " {'label': 'ang', 'score': 0.26151540875434875},\n",
       " {'label': 'ang', 'score': 0.2678190767765045},\n",
       " {'label': 'ang', 'score': 0.26647165417671204},\n",
       " {'label': 'ang', 'score': 0.2715841233730316},\n",
       " {'label': 'ang', 'score': 0.2684396505355835},\n",
       " {'label': 'ang', 'score': 0.26723194122314453},\n",
       " {'label': 'ang', 'score': 0.2704460918903351},\n",
       " {'label': 'ang', 'score': 0.26535719633102417},\n",
       " {'label': 'ang', 'score': 0.26061636209487915},\n",
       " {'label': 'sad', 'score': 0.26568612456321716},\n",
       " {'label': 'sad', 'score': 0.27805402874946594},\n",
       " {'label': 'ang', 'score': 0.26809072494506836},\n",
       " {'label': 'sad', 'score': 0.2649749517440796},\n",
       " {'label': 'sad', 'score': 0.27130022644996643},\n",
       " {'label': 'ang', 'score': 0.2683080732822418},\n",
       " {'label': 'sad', 'score': 0.26423415541648865},\n",
       " {'label': 'ang', 'score': 0.27111372351646423},\n",
       " {'label': 'ang', 'score': 0.26863089203834534},\n",
       " {'label': 'ang', 'score': 0.26732540130615234},\n",
       " {'label': 'ang', 'score': 0.26452088356018066},\n",
       " {'label': 'ang', 'score': 0.26593494415283203},\n",
       " {'label': 'ang', 'score': 0.26278412342071533},\n",
       " {'label': 'ang', 'score': 0.2687623202800751},\n",
       " {'label': 'ang', 'score': 0.2641953229904175},\n",
       " {'label': 'ang', 'score': 0.2655779719352722},\n",
       " {'label': 'ang', 'score': 0.2638562023639679},\n",
       " {'label': 'ang', 'score': 0.2622520625591278},\n",
       " {'label': 'ang', 'score': 0.26517751812934875},\n",
       " {'label': 'ang', 'score': 0.2661006450653076},\n",
       " {'label': 'ang', 'score': 0.2623174786567688},\n",
       " {'label': 'ang', 'score': 0.2606176733970642},\n",
       " {'label': 'sad', 'score': 0.27077412605285645},\n",
       " {'label': 'ang', 'score': 0.2573181688785553},\n",
       " {'label': 'ang', 'score': 0.2682317793369293},\n",
       " {'label': 'ang', 'score': 0.26881369948387146},\n",
       " {'label': 'ang', 'score': 0.2719399929046631},\n",
       " {'label': 'ang', 'score': 0.26943379640579224},\n",
       " {'label': 'ang', 'score': 0.2666497528553009},\n",
       " {'label': 'ang', 'score': 0.2664859890937805},\n",
       " {'label': 'ang', 'score': 0.2727954387664795},\n",
       " {'label': 'ang', 'score': 0.2648254632949829},\n",
       " {'label': 'ang', 'score': 0.26657527685165405},\n",
       " {'label': 'sad', 'score': 0.2657243609428406},\n",
       " {'label': 'ang', 'score': 0.2654300630092621},\n",
       " {'label': 'ang', 'score': 0.2707122564315796},\n",
       " {'label': 'sad', 'score': 0.2633555829524994},\n",
       " {'label': 'ang', 'score': 0.26306816935539246},\n",
       " {'label': 'sad', 'score': 0.2666711211204529},\n",
       " {'label': 'ang', 'score': 0.2722596228122711},\n",
       " {'label': 'ang', 'score': 0.27490484714508057},\n",
       " {'label': 'ang', 'score': 0.26480451226234436},\n",
       " {'label': 'ang', 'score': 0.2648542523384094},\n",
       " {'label': 'ang', 'score': 0.2680184543132782},\n",
       " {'label': 'ang', 'score': 0.267879843711853},\n",
       " {'label': 'ang', 'score': 0.26420050859451294},\n",
       " {'label': 'sad', 'score': 0.2727327346801758},\n",
       " {'label': 'ang', 'score': 0.2694713771343231},\n",
       " {'label': 'sad', 'score': 0.26338133215904236},\n",
       " {'label': 'ang', 'score': 0.270205020904541},\n",
       " {'label': 'sad', 'score': 0.2601032257080078},\n",
       " {'label': 'ang', 'score': 0.25916263461112976},\n",
       " {'label': 'sad', 'score': 0.25707611441612244},\n",
       " {'label': 'ang', 'score': 0.26292893290519714},\n",
       " {'label': 'sad', 'score': 0.2635103464126587},\n",
       " {'label': 'ang', 'score': 0.26729145646095276},\n",
       " {'label': 'ang', 'score': 0.2600683271884918},\n",
       " {'label': 'sad', 'score': 0.2644779086112976},\n",
       " {'label': 'sad', 'score': 0.26717230677604675},\n",
       " {'label': 'ang', 'score': 0.2653181552886963},\n",
       " {'label': 'ang', 'score': 0.2635039985179901},\n",
       " {'label': 'ang', 'score': 0.26883217692375183},\n",
       " {'label': 'ang', 'score': 0.2655670642852783},\n",
       " {'label': 'ang', 'score': 0.27024415135383606},\n",
       " {'label': 'ang', 'score': 0.2669820785522461},\n",
       " {'label': 'ang', 'score': 0.26599612832069397},\n",
       " {'label': 'ang', 'score': 0.2616436183452606},\n",
       " {'label': 'ang', 'score': 0.2663658559322357},\n",
       " {'label': 'ang', 'score': 0.2611772119998932},\n",
       " {'label': 'ang', 'score': 0.2694713771343231},\n",
       " {'label': 'sad', 'score': 0.2694416344165802},\n",
       " {'label': 'ang', 'score': 0.27083003520965576},\n",
       " {'label': 'sad', 'score': 0.2685350179672241},\n",
       " {'label': 'sad', 'score': 0.266326367855072},\n",
       " {'label': 'ang', 'score': 0.26827749609947205},\n",
       " {'label': 'ang', 'score': 0.26213952898979187},\n",
       " {'label': 'ang', 'score': 0.2759074866771698},\n",
       " {'label': 'ang', 'score': 0.27032312750816345},\n",
       " {'label': 'ang', 'score': 0.2652939260005951},\n",
       " {'label': 'ang', 'score': 0.2655927836894989},\n",
       " {'label': 'sad', 'score': 0.26278722286224365},\n",
       " {'label': 'ang', 'score': 0.26669231057167053},\n",
       " {'label': 'sad', 'score': 0.2746938169002533},\n",
       " {'label': 'ang', 'score': 0.2721194326877594},\n",
       " {'label': 'ang', 'score': 0.2668715715408325},\n",
       " {'label': 'sad', 'score': 0.2621140480041504},\n",
       " {'label': 'sad', 'score': 0.2613101005554199},\n",
       " {'label': 'ang', 'score': 0.265055775642395},\n",
       " {'label': 'ang', 'score': 0.2660564184188843},\n",
       " {'label': 'sad', 'score': 0.2550843358039856},\n",
       " {'label': 'ang', 'score': 0.26680099964141846},\n",
       " {'label': 'ang', 'score': 0.2642801105976105},\n",
       " {'label': 'ang', 'score': 0.2576380670070648},\n",
       " {'label': 'ang', 'score': 0.2665357291698456},\n",
       " {'label': 'ang', 'score': 0.2677834630012512},\n",
       " {'label': 'ang', 'score': 0.26776883006095886},\n",
       " {'label': 'ang', 'score': 0.2762385606765747},\n",
       " {'label': 'ang', 'score': 0.2705899775028229},\n",
       " {'label': 'ang', 'score': 0.26384690403938293},\n",
       " {'label': 'ang', 'score': 0.2677554190158844},\n",
       " {'label': 'sad', 'score': 0.26819562911987305},\n",
       " {'label': 'ang', 'score': 0.26869094371795654},\n",
       " {'label': 'ang', 'score': 0.2691303491592407},\n",
       " {'label': 'sad', 'score': 0.2626473903656006},\n",
       " {'label': 'sad', 'score': 0.26738137006759644},\n",
       " {'label': 'ang', 'score': 0.26875075697898865},\n",
       " {'label': 'ang', 'score': 0.2705860137939453},\n",
       " {'label': 'ang', 'score': 0.26758527755737305},\n",
       " {'label': 'sad', 'score': 0.26575928926467896},\n",
       " {'label': 'sad', 'score': 0.2760188579559326},\n",
       " {'label': 'sad', 'score': 0.27367857098579407},\n",
       " {'label': 'sad', 'score': 0.2684383988380432},\n",
       " {'label': 'sad', 'score': 0.26659640669822693},\n",
       " {'label': 'sad', 'score': 0.2650526762008667},\n",
       " {'label': 'sad', 'score': 0.2780974507331848},\n",
       " {'label': 'ang', 'score': 0.26213616132736206},\n",
       " {'label': 'ang', 'score': 0.2736422121524811},\n",
       " {'label': 'sad', 'score': 0.2678970992565155},\n",
       " {'label': 'ang', 'score': 0.2656114101409912},\n",
       " {'label': 'sad', 'score': 0.2654498815536499},\n",
       " {'label': 'ang', 'score': 0.26962810754776},\n",
       " {'label': 'ang', 'score': 0.2635757327079773},\n",
       " {'label': 'sad', 'score': 0.270617812871933},\n",
       " {'label': 'ang', 'score': 0.26530638337135315},\n",
       " {'label': 'sad', 'score': 0.26258936524391174},\n",
       " {'label': 'ang', 'score': 0.2637310028076172},\n",
       " {'label': 'ang', 'score': 0.2665320932865143},\n",
       " {'label': 'ang', 'score': 0.2661580443382263},\n",
       " {'label': 'sad', 'score': 0.26623106002807617},\n",
       " {'label': 'sad', 'score': 0.2632434368133545},\n",
       " {'label': 'ang', 'score': 0.2685132324695587},\n",
       " {'label': 'ang', 'score': 0.266783207654953},\n",
       " {'label': 'ang', 'score': 0.266332745552063},\n",
       " {'label': 'hap', 'score': 0.25866591930389404},\n",
       " {'label': 'sad', 'score': 0.2780974507331848},\n",
       " {'label': 'sad', 'score': 0.2697460651397705},\n",
       " {'label': 'ang', 'score': 0.2622486650943756},\n",
       " {'label': 'ang', 'score': 0.2720155715942383},\n",
       " {'label': 'ang', 'score': 0.2700057923793793},\n",
       " {'label': 'sad', 'score': 0.2661636471748352},\n",
       " {'label': 'ang', 'score': 0.2591601610183716},\n",
       " {'label': 'sad', 'score': 0.26747095584869385},\n",
       " {'label': 'ang', 'score': 0.2640630602836609},\n",
       " {'label': 'sad', 'score': 0.26344728469848633},\n",
       " {'label': 'ang', 'score': 0.27020666003227234},\n",
       " {'label': 'ang', 'score': 0.270160049200058},\n",
       " {'label': 'ang', 'score': 0.26532182097435},\n",
       " {'label': 'ang', 'score': 0.26347801089286804},\n",
       " {'label': 'ang', 'score': 0.26737335324287415},\n",
       " {'label': 'ang', 'score': 0.2679482698440552},\n",
       " {'label': 'ang', 'score': 0.26895371079444885},\n",
       " {'label': 'sad', 'score': 0.2642074227333069},\n",
       " {'label': 'ang', 'score': 0.2621493637561798},\n",
       " {'label': 'ang', 'score': 0.2624841034412384},\n",
       " {'label': 'ang', 'score': 0.26368144154548645},\n",
       " {'label': 'ang', 'score': 0.266533225774765},\n",
       " {'label': 'ang', 'score': 0.26305168867111206},\n",
       " {'label': 'sad', 'score': 0.26199871301651},\n",
       " {'label': 'ang', 'score': 0.27574923634529114},\n",
       " {'label': 'ang', 'score': 0.27032235264778137},\n",
       " {'label': 'ang', 'score': 0.2635822296142578},\n",
       " {'label': 'ang', 'score': 0.26885664463043213},\n",
       " {'label': 'sad', 'score': 0.2640438377857208},\n",
       " {'label': 'ang', 'score': 0.26765716075897217},\n",
       " {'label': 'ang', 'score': 0.2711382210254669},\n",
       " {'label': 'ang', 'score': 0.2676449120044708},\n",
       " {'label': 'ang', 'score': 0.26519498229026794},\n",
       " {'label': 'sad', 'score': 0.2619226574897766},\n",
       " {'label': 'ang', 'score': 0.26912549138069153},\n",
       " {'label': 'sad', 'score': 0.2656500041484833},\n",
       " {'label': 'ang', 'score': 0.27087530493736267},\n",
       " {'label': 'sad', 'score': 0.2772518992424011},\n",
       " {'label': 'ang', 'score': 0.259184867143631},\n",
       " {'label': 'ang', 'score': 0.2681227922439575},\n",
       " {'label': 'ang', 'score': 0.2642935514450073},\n",
       " {'label': 'ang', 'score': 0.2653449475765228},\n",
       " {'label': 'ang', 'score': 0.2663177251815796},\n",
       " {'label': 'ang', 'score': 0.26737192273139954},\n",
       " {'label': 'ang', 'score': 0.26720261573791504},\n",
       " {'label': 'ang', 'score': 0.26564857363700867},\n",
       " {'label': 'sad', 'score': 0.2705875039100647},\n",
       " {'label': 'sad', 'score': 0.2665103077888489},\n",
       " {'label': 'sad', 'score': 0.2564558982849121},\n",
       " {'label': 'sad', 'score': 0.275943398475647},\n",
       " {'label': 'ang', 'score': 0.2769913673400879},\n",
       " {'label': 'ang', 'score': 0.26792314648628235},\n",
       " {'label': 'sad', 'score': 0.2638287842273712}]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "b9d9e09e-d78e-49da-a9b3-18a15d56e5a9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1,\n",
       " 2,\n",
       " 3,\n",
       " 1,\n",
       " 3,\n",
       " 2,\n",
       " 2,\n",
       " 1,\n",
       " 3,\n",
       " 2,\n",
       " 1,\n",
       " 2,\n",
       " 0,\n",
       " 3,\n",
       " 2,\n",
       " 3,\n",
       " 0,\n",
       " 2,\n",
       " 1,\n",
       " 1,\n",
       " 3,\n",
       " 1,\n",
       " 0,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 0,\n",
       " 3,\n",
       " 0,\n",
       " 2,\n",
       " 1,\n",
       " 1,\n",
       " 2,\n",
       " 1,\n",
       " 1,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 1,\n",
       " 1,\n",
       " 2,\n",
       " 2,\n",
       " 0,\n",
       " 2,\n",
       " 2,\n",
       " 0,\n",
       " 2,\n",
       " 2,\n",
       " 1,\n",
       " 3,\n",
       " 2,\n",
       " 3,\n",
       " 2,\n",
       " 2,\n",
       " 3,\n",
       " 1,\n",
       " 0,\n",
       " 2,\n",
       " 3,\n",
       " 2,\n",
       " 0,\n",
       " 2,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 2,\n",
       " 3,\n",
       " 3,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 2,\n",
       " 3,\n",
       " 2,\n",
       " 2,\n",
       " 1,\n",
       " 2,\n",
       " 3,\n",
       " 2,\n",
       " 3,\n",
       " 2,\n",
       " 2,\n",
       " 0,\n",
       " 3,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 2,\n",
       " 0,\n",
       " 1,\n",
       " 3,\n",
       " 0,\n",
       " 3,\n",
       " 2,\n",
       " 3,\n",
       " 2,\n",
       " 0,\n",
       " 2,\n",
       " 0,\n",
       " 0,\n",
       " 2,\n",
       " 2,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 2,\n",
       " 1,\n",
       " 3,\n",
       " 2,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 2,\n",
       " 1,\n",
       " 2,\n",
       " 3,\n",
       " 1,\n",
       " 3,\n",
       " 3,\n",
       " 1,\n",
       " 2,\n",
       " 0,\n",
       " 2,\n",
       " 1,\n",
       " 2,\n",
       " 1,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 3,\n",
       " 1,\n",
       " 0,\n",
       " 3,\n",
       " 2,\n",
       " 0,\n",
       " 2,\n",
       " 1,\n",
       " 1,\n",
       " 3,\n",
       " 2,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 2,\n",
       " 2,\n",
       " 1,\n",
       " 3,\n",
       " 3,\n",
       " 2,\n",
       " 1,\n",
       " 0,\n",
       " 2,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 2,\n",
       " 2,\n",
       " 3,\n",
       " 1,\n",
       " 1,\n",
       " 3,\n",
       " 1,\n",
       " 2,\n",
       " 1,\n",
       " 2,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 2,\n",
       " 3,\n",
       " 0,\n",
       " 3,\n",
       " 0,\n",
       " 2,\n",
       " 2,\n",
       " 3,\n",
       " 1,\n",
       " 1,\n",
       " 2,\n",
       " 0,\n",
       " 3,\n",
       " 0,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 1,\n",
       " 3,\n",
       " 3,\n",
       " 1,\n",
       " 0,\n",
       " 2,\n",
       " 3,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 2,\n",
       " 2,\n",
       " 3,\n",
       " 1,\n",
       " 0,\n",
       " 2,\n",
       " 1,\n",
       " 2,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 2,\n",
       " 1,\n",
       " 3,\n",
       " 3,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 3,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 1,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 3,\n",
       " 2,\n",
       " 0,\n",
       " 2,\n",
       " 1,\n",
       " 0,\n",
       " 2,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 3,\n",
       " 3,\n",
       " 1,\n",
       " 3,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 2,\n",
       " 1,\n",
       " 0,\n",
       " 2,\n",
       " 1,\n",
       " 1,\n",
       " 2,\n",
       " 2,\n",
       " 3,\n",
       " 0,\n",
       " 2,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 3,\n",
       " 3,\n",
       " 2,\n",
       " 3,\n",
       " 0,\n",
       " 0,\n",
       " 3,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 3,\n",
       " 2,\n",
       " 1,\n",
       " 1,\n",
       " 3,\n",
       " 1,\n",
       " 2,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 2,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 3,\n",
       " 2,\n",
       " 2,\n",
       " 3,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 2,\n",
       " 3,\n",
       " 3,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 1,\n",
       " 0,\n",
       " 2,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 2,\n",
       " 3,\n",
       " 2,\n",
       " 0,\n",
       " 1,\n",
       " 2,\n",
       " 3,\n",
       " 3,\n",
       " 1,\n",
       " 1,\n",
       " 2,\n",
       " 0,\n",
       " 1,\n",
       " 2,\n",
       " 1,\n",
       " 0,\n",
       " 2,\n",
       " 0,\n",
       " 2,\n",
       " 1,\n",
       " 1,\n",
       " 2,\n",
       " 0,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 2,\n",
       " 0,\n",
       " 2,\n",
       " 3,\n",
       " 1,\n",
       " 2,\n",
       " 2,\n",
       " 1,\n",
       " 2,\n",
       " 1,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 0,\n",
       " 2,\n",
       " 2,\n",
       " 3,\n",
       " 0,\n",
       " 2,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 2,\n",
       " 3,\n",
       " 3,\n",
       " 2,\n",
       " 2,\n",
       " 1,\n",
       " 0,\n",
       " 3,\n",
       " 0,\n",
       " 1,\n",
       " 3,\n",
       " 1,\n",
       " 3,\n",
       " 3,\n",
       " 0,\n",
       " 3,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 3,\n",
       " 1,\n",
       " 0,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 2,\n",
       " 0,\n",
       " 0,\n",
       " 2,\n",
       " 2,\n",
       " 1,\n",
       " 2,\n",
       " 1,\n",
       " 3,\n",
       " 0,\n",
       " 2,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 2,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 2,\n",
       " 0,\n",
       " 3,\n",
       " 3,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 1,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 0,\n",
       " 0,\n",
       " 2,\n",
       " 0,\n",
       " 3,\n",
       " 1,\n",
       " 2,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 2,\n",
       " 3,\n",
       " 0,\n",
       " 1,\n",
       " 2,\n",
       " 2,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 3,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 3,\n",
       " 2,\n",
       " 3,\n",
       " 1,\n",
       " 2,\n",
       " 2,\n",
       " 3,\n",
       " 2,\n",
       " 1,\n",
       " 3,\n",
       " 2,\n",
       " 1,\n",
       " 0,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 1,\n",
       " 2,\n",
       " 1,\n",
       " 2,\n",
       " 1,\n",
       " 2,\n",
       " 2,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 2,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 3,\n",
       " 1,\n",
       " 0,\n",
       " 3,\n",
       " 0,\n",
       " 3,\n",
       " 3,\n",
       " 1,\n",
       " 0,\n",
       " 3,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 3,\n",
       " 2,\n",
       " 3,\n",
       " 3,\n",
       " 1,\n",
       " 2,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 2,\n",
       " 1,\n",
       " 0,\n",
       " 3,\n",
       " 1,\n",
       " 3,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 2,\n",
       " 2,\n",
       " 0,\n",
       " 1,\n",
       " 2,\n",
       " 3,\n",
       " 1,\n",
       " 1,\n",
       " 2,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 2,\n",
       " 1,\n",
       " 3,\n",
       " 2,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 3,\n",
       " 1,\n",
       " 2,\n",
       " 3,\n",
       " 1]"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenized_datasets[\"test\"][\"label\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "7628d40c-77bf-47e5-bbd2-1fe78972b544",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    label     score\n",
      "0     ang  0.262280\n",
      "1     ang  0.270501\n",
      "2     ang  0.271913\n",
      "3     ang  0.264391\n",
      "4     ang  0.261398\n",
      "..    ...       ...\n",
      "549   sad  0.256456\n",
      "550   sad  0.275943\n",
      "551   ang  0.276991\n",
      "552   ang  0.267923\n",
      "553   sad  0.263829\n",
      "\n",
      "[554 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df = pd.DataFrame.from_records(dd)\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b8b89b4-5aab-4139-8afc-e6182756f546",
   "metadata": {},
   "outputs": [],
   "source": [
    "hub_model(tokenized_datasets[\"test\"][0][\"text\"])[0][\"label\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ff6b896",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(277):\n",
    "    actual_emo = id2label_fn(tokenized_datasets['test'][i]['label'])\n",
    "    pred_emo = id2label_fn(hub_model(tokenized_datasets[\"test\"][i][\"text\"])[0][\"label\"])\n",
    "    print(f\"Text: {tokenized_datasets['test'][i]['text']}\\nActual Label: {actual_emo}\\nPredicted Label: {pred_emo}\\n\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae164eed-c063-4ae7-8388-49cf384687aa",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
